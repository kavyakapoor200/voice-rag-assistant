# ğŸ¤ Voice-Based RAG Assistant

A production-style **Voice Retrieval-Augmented Generation (RAG)** system that answers user questions **strictly from uploaded audio content**, ensuring **hallucination-free responses** using LLMs.

ğŸ”— **Live Demo**: Hugging Face Spaces (link in About section)

---

## ğŸ“Œ What This Project Does

Users upload an audio file (lecture, meeting, podcast, etc.) and ask questions via text.
The system **transcribes the audio**, retrieves relevant context, and generates answers **only from the audio**, refusing to guess when information is missing.

---

## ğŸš€ Key Features

* ğŸ§ Audio-based question answering
* ğŸ§  Retrieval-Augmented Generation (RAG)
* ğŸ›¡ï¸ Strict hallucination control
* ğŸ” Multi-turn conversational support
* âš¡ Fast semantic search using embeddings
* ğŸŒ Deployed interactive UI

---

## ğŸ§  How It Works (Simple Flow)

```
Audio Upload
   â†“
Speech-to-Text (Whisper)
   â†“
Text Chunking
   â†“
Embeddings Generation
   â†“
Vector Store (Similarity Search)
   â†“
LLM Answer (Strictly from Audio)
```

---

## ğŸ› ï¸ Tech Stack

* **Language**: Python
* **LLM**: LLaMA 3.1 (via Groq)
* **Speech-to-Text**: Whisper (Groq)
* **RAG Framework**: LangChain
* **Embeddings**: Hugging Face (MiniLM)
* **Vector Store**: In-Memory Vector Store
* **UI**: Gradio
* **Deployment**: Hugging Face Spaces

---

## ğŸ›¡ï¸ Hallucination Control

* The LLM is prompted to **answer only from retrieved transcript chunks**
* If relevant context is missing, the system replies:

  > *â€œI donâ€™t know based on the audio.â€*
* Additional safety checks block speculative responses

This makes the system suitable for **enterprise, education, and internal knowledge tools**.

---

## ğŸ“¦ Installation (Run Locally)

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/kavyakapoor200/voice-rag-assistant.git
cd voice-rag-assistant
```

---

### 2ï¸âƒ£ Create & activate virtual environment (recommended)

```bash
python -m venv venv
```

**Windows**

```bash
venv\Scripts\activate
```

**Mac / Linux**

```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Set environment variables

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_groq_api_key
```

---

### 5ï¸âƒ£ Run the application

```bash
python app.py
```

The Gradio interface will open in your browser.

---

## ğŸ§ª Testing

Sample audio files are included in the `audios/` directory for quick testing.
Upload an audio file and start asking questions.

---

## ğŸ¯ Why This Project Matters

Most LLM assistants hallucinate.
This project demonstrates how **RAG systems can ground LLM responses in real data**, making AI outputs reliable, explainable, and production-ready.

---

## ğŸ“š Key Learnings

* Designing end-to-end RAG pipelines
* Preventing hallucinations in LLM applications
* Semantic search with embeddings
* Building and deploying AI systems
* Separating UI and backend logic for scalability

---

## ğŸ”® Future Improvements

* Persistent vector databases (FAISS / ChromaDB)
* Multi-language audio support
* Streaming audio input
* Speaker diarization

---

## ğŸ‘©â€ğŸ’» Author

**Kavya Kapoor**
AI Engineer | Generative AI | RAG Systems

---
